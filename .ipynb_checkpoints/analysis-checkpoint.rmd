---
  title: 'DSCI 310 Group 2'
author: ""
output:
  bookdown::html_document2:
  toc: true
toc_depth: 2
bookdown::pdf_document2:
  toc: true
toc_depth: 2
---
  
# Predicting Heart Disease
# Summary
Introduction
Heart disease is an umbrella term that refers to several conditions that affect the health of one's heart. Common heart diseases include disease of the blood vessel, arrhythmia (irregular beating of the heart), disease of the heart valve and muscle, infection of the heart, and heart defects from birth (“Heart Disease.”). The symptoms of one’s heart disease is very dependent on the type of disease they have, however many forms can be prevented with healthy lifestyle choices. Most heart diseases (with the exception of serious defects at birth) are only diagnosed after a heart attack, heart failure, or stroke (“Heart Disease.”). Heart attacks, heart failure, and strokes are very traumatic events to go through and are oftentimes deadly (“Heart Disease and Stroke.”). Therefore it is very important that we are able to predict if an individual is at an increased risk of heart disease and try to get them preventable care. In this project we want to determine if we can predict if someone is at risk of a heart disease based on the following variables.

We used data from UCI Machine Learning (https://archive-beta.ics.uci.edu/ml/datasets/heart+disease). The Cleveland Heart Disease dataset consists of 13 explanatory variables and 1 target class. The variables, variable type and a brief description of each variable are listed below.

Figure 1: Variable Descriptions

# Methods & Results
We started by loading the heart disease data set and adding a column headers. The database has 14 features. For the purpose of this analysis, we have focused on the Diagnosis feature. Based on the data description, any value over 0 has a heart disease and 0 indicates no presence of heart disease.

We grouped the data by its diagnosis. Then we applied data cleaning. We checked for the data type and for any mistakes about the characters. We further dealt with the NA values.

Packages

library(tidyverse)
library(tidymodels)
library(ggplot2)
library(GGally)

source("../R/clean_data.r")
source("../R/accuracy_plot.r")
source("../R/diagnosis.r")
source("../R/attribe_box_plots.r")

heart_disease <- read.csv("../data/processed-cleveland.csv", header = FALSE)

Before any data analysis can be done, the data needs to be cleaned. The downloaded data does not have any column names so first we need to add all the variables to their respective column.

colnames(heart_disease) <- c("age",
                             "sex",
                             "chest_pain",
                             "resting_blood_pressure",
                             "serum_cholesterol",
                             "fasting_blood_sugar",
                             "resting_ecg",
                             "max_heart_rate",
                             "exercise_induced_angina",
                             "oldpeak",
                             "slope",
                             "num_of_major_vessels",
                             "thalassemia",
                             "diagnosis")

head(heart_disease, 10)

The next step in cleaning up the data is to check for NAs. It is important that we remove these before any data analysis so that the functions we use will run on the data properly. Using the colMeans function we get the percentage of NAs in each column.

colMeans(is.na(heart_disease))

As we can see above, it looks like we have no NAs in our data. However on the UCI ML website, we know that our data has missing values.

unique(heart_disease)

Instead of R recognizing our missing values, we have a question mark. We need to convert this to an actual NA that R will recognize.

heart_disease_clean <- clean_data(heart_disease)

Now if we run our colMeans function again we will see that we do have missing values in num_of_major_vessels and thalassemia. We now need to remove these missing values.

colMeans(is.na(heart_disease_clean))

Since the mean of each column is 0 we can tell that there are no more missing values in our dataset.

# Exploring Dataset
Next we need to get to know our data. We will do this by performing exploratory analysis where we summarize our data and graph a few relevant figures. The aim of doing this is to get a better understanding of what our final classification analysis will look like.

The glimpsefunction allows us to easy tell what type of data we have (i.e. are variables made of integers or characters). This is especially important for our dataset since we have categorical data that is separated into groups with numerical values, for example there are three categories in a given variable and they are given a label from 1 to 3.

glimpse(heart_disease_clean)

We know that sex, chest_pain, fasting_blood_sugar, resting_ecg, exercise_induced_angina and slope are all categorical variables but we can see that R is interpreting them are quantitative variables. It is important for us keep this in mind when we process our data. Additionally we can see that in this dataset num_of_major_vessels and thalassemia are characters. Since num_of_major_vessels is a quantitative variable we will be converting this to a numerical type. We will also convert all the categorical variables into factor types.

One thing to note is that our target class (diagnosis) has values from 0 to 4 where 0 means that heart disease was not present and 1-4 indicate increasing severity of the heart disease. For this analysis we will combine all instances where heart disease was present and represent that with a value of 1. We will do this with our custom diagnosis function. This function finds all instances of heart disease (1-4) and replaces them with the number 1 to indicate the presence of heart disease in a patient.

heart_disease_clean <- heart_disease_clean %>%
  mutate(num_of_major_vessels = as.numeric(num_of_major_vessels)) %>%
  diagnosis()


#code inspired by: https://stackoverflow.com/questions/35426903/change-class-of-multiple-columns-in-data-frame-without-for-loop
heart_disease_clean[,c(2:3, 6:7, 9, 11, 13:14)] <- lapply(heart_disease_clean[,c(2:3, 6:7, 9, 11, 13:14)], as.factor)



glimpse(heart_disease_clean)


summary(heart_disease) #summary

Since this project should be in the scope of DSCI 100 and we did not learn how to use one hot encoding to deal with categorical variables, we will drop all the categorical variables from our dataset.

heart_disease_numerical <- heart_disease_clean[ -c(2:3, 6:7, 9, 11, 13)]

glimpse(heart_disease_numerical)

attribute_box_plots(heart_disease_numerical, diagnosis)

Through this plot we can see that the most common age to have a heart disease ranges from 55 to 60 and looking at the outliers

We grouped the data by its diagnosis and graphed it in order for us to see if the dataset is balanced or not.

num_obs <- nrow(heart_disease_clean)
diagnosis_heart_disease <- group_by(heart_disease_clean, diagnosis) %>%
  summarize(count = n(),
            percentage = n() / num_obs * 100)
diagnosis_heart_disease


pie(table(heart_disease_clean$diagnosis), main = "Figure 3: Distribution of Diagnosis", col = c("Blue", "Red"))

As we can see the data looks fairly balanced.

ggcorr(heart_disease_numerical, label = TRUE, label_size = 4, label_round = 2, label_alpha = FALSE) + 
  ggplot2::labs(title = "Figure 4: Correlation between Variables")


In figure 4 we can see that most variables look like they have some correlation save for serum_cholesterol and max_heart_rate. While the correlations may not look very high, this is actually a good sign because highly correlated variables can lead to overly complicated models.

# Classification Analysis
Now that we have done our exploratory analysis we can begin training our classification model.

First we need to split our data. We do this so that after we create our model we can find the accuracy of our classifier.

set.seed(321)

heart_disease_split <- initial_split(heart_disease_numerical, prop = 0.75, strata = diagnosis)
hd_train <- training(heart_disease_split)
hd_test <- testing(heart_disease_split)

Next we perform cross validation for our data. This is important because it allows us to get a more accurate idea of how our classifier is doing. If we did not use cross validation our classifier might be biased from an unbalanced validation set without us knowing. We are preprocess the data by creating a recipe. This step allows us to standardize our predictors so that any one predictor is not disproportionately affecting the classifier even if it has a larger number.

set.seed(321)

hd_vfold <- vfold_cv(hd_train, v = 5, strata = diagnosis)


recipe <- recipe(diagnosis ~ ., data = hd_train) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors())

Next we create our classifier. The only parameter we can tune is the number of classifier we have. We are tuning our classifier to get the optimal number of neighbors as to increase accuracy.

set.seed(321)

knn_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("classification")


set.seed(321)

k_vals <- tibble(neighbors = seq(from = 1, to = 100, by = 5))

knn_results <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(knn_spec) %>%
  tune_grid(resamples = hd_vfold, grid = k_vals) %>%
  collect_metrics() 

accuracies <- knn_results %>%
  filter(.metric == "accuracy")

set.seed(321)

accuracy_vs_k <- accuracy_plot(accuracies)

accuracy_vs_k

"From our graph above we can see that our accuracy peaks at around 12-13 neighbors. Therefore we will use that in our new classifier that we will use to predict."

set.seed(321)

knn_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = 12) %>%
  set_engine("kknn") %>%
  set_mode("classification")

set.seed(321)

knn_fit <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(knn_spec) %>%
  fit(data = hd_train)

set.seed(321)

hd_predictions <- predict(knn_fit, hd_test)  %>%
  bind_cols(hd_test)


hd_predictions %>%
  metrics(truth = diagnosis, estimate = .pred_class) %>%
  filter(.metric == "accuracy")

confusion_mat <- hd_predictions %>%
  conf_mat(truth = diagnosis, estimate = .pred_class)

print("Figure 6: Confusion Matrix of Results")
confusion_mat


The confusion matrix above shows us that a majority of the predictions were given the right label. However we also see that the model is more likely to predict a false negative than a false positive.

# Discussion
In this project, we used 13 attributes to predict whether a person has heart disease or not. Many contributing factors can be considered for this prediction. Age is one of them. Based on our results, we saw that heart disease is more common among people between 55 to 60 years old. This aligns with our expectation that most heart disease diagnosis is in middle-aged people. We also saw that the other explanatory variables (resting_blood_pressure, serum_cholesterol, max_heart_rate, oldpeak, and num_of_major_vessels) can also be used to train a classification model and predict heart disease in people. We used the K-nearest neighbors algorithm for our classification. This is a simple and intuitive algorithm that works perfectly with our two-class classification problem. However we found that our accuracy was low (73%). This could be due to us dropping many categorical variables. Variables such as if the patient had chest pain, angina, or thalessemia could be very important in determining if they get heart disease ("Angina."). Thus we might have seen higher accuracy if we were able to use these variables.

In future studies, we could use more complex methods to increase the accuracy of our model. Predicting heart disease is remarkably useful for heart disease awareness. Early heart disease detection can be crucial for the treatment process and can save lives. Following our predictions, one can be advised to do checkups and detect early signs of heart diseases and start the treatment early (“The Importance of Early Detection.”).

For future studies, one can study the difference between the contribution of these factors in heart disease detection. Our prediction model predicts more false negatives than false positives. This is not good because the prediction may suggest one has no heart disease who in fact has the disease. Therefore, in further studies, we can focus on building a more accurate model and decrease our amounts of false negatives. Having false positives, on the other hand, is not crucial to be taken care of since one may be a person prone to heart disease and can be advised to be more cautious and do more regular checkups. In this study, we focused on the numerical variables. For more accurate predictions, one can consider those categorical variables contributing to the presence of heart disease which can lead to a more reliable prediction.


# References
“Angina.” Mayo Clinic, Mayo Foundation for Medical Education and Research, 12 June 2020, https://www.mayoclinic.org/diseases-conditions/angina/symptoms-causes/syc-20369373.

“Cleveland Heart Disease Dataset.” UCI Machine Learning Repository, https://archive-beta.ics.uci.edu/ml/datasets/heart+disease.

“Heart Disease and Stroke.” Centers for Disease Control and Prevention, Centers for Disease Control and Prevention, 27 Jan. 2022, https://www.cdc.gov/chronicdisease/resources/publications/factsheets/heart-disease-stroke.htm.

“Heart Disease.” Mayo Clinic, Mayo Foundation for Medical Education and Research, 9 Feb. 2021, https://www.mayoclinic.org/diseases-conditions/heart-disease/symptoms-causes/syc-20353118.

“The Importance of Early Detection.” Jupiter Medical Center, https://www.jupitermed.com/news-press-releases/2020/june/the-importance-of-early-detection/.

ScransomScransom 2. “Change Class of Multiple Columns in Data Frame without for Loop.” Stack Overflow, 1 Jan. 1964, https://stackoverflow.com/questions/35426903/change-class-of-multiple-columns-in-data-frame-without-for-loop.


